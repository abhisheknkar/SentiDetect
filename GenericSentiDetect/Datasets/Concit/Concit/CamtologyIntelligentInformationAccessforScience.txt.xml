<annotatedpaper> 
    <paper title="Camtology: Intelligent Information Access for Science" authors="Ted Briscoe, Karl Harrison, Andrew Naish-Guzman, Andy Parker, Advaith Siddharthan, David Sinclair, Mark Slater, Rebecca Watson" year="2010" >
        <section> 
            <title>Camtology: Intelligent Information Access for Science</title> 
            Ted Briscoe, Karl Harrison, Andrew Naish-Guzman, Andy Parker 
            Advaith Siddharthan, David Sinclair, Mark Slater and Rebecca Watson 
 
            University of Cambridge 
            ejb1@cl.cam.ac.uk, 
            parker@hep.phy.cam.ac.uk, 
 
            iLexIR Ltd 
            rfw@ilexir.co.uk 
            University of Aberdeen 
            advaith@abdn.ac.uk 
 
            Camtology Ltd 
            david.sinclair@imense.co.uk, 
            a.naish@gmail.com 
 
            University of Birmingham 
            kh@hep.ph.bham.ac.uk, 
            mws@hep.ph.bham.ac.uk 
        </section> 
 
        <section> 
            <title>Abstract</title> 
            <paragraph> 
                We describe a novel semantic search engine for scientific literature. 
                The Camtology system allows for sentence-level searches ofPDF files and combines text and image searches, thus facilitating the retrieval of information present in tables and figures. 
                It allows the user to generate complex queries for search terms that are related through particular grammatical/semantic relations in an intuitive manner. 
                The system uses Grid processing to parallelise the analysis of large numbers of papers. 
            </paragraph> 
        </section> 
        <section imrad="i"> 
            <title>1 Introduction</title> 
            <paragraph> 
                Scientific, technological, engineering and medical (STEM) research is entering the so-called 4th Paradigm of "data-intensive scientific discovery", in which advanced data mining and pattern discovery techniques need to be applied to vast datasets in order to drive further discoveries. 
                A key component of this process is efficient search and exploitation of the huge repository of information that only exists in textual or visual form within the "bibliome", which itself continues to grow exponentially. 
            </paragraph> 
            <paragraph> 
                Today's computationally driven research methods have outgrown traditional methods of searching for scientific data, creating a widespread and unfulfilled need for advanced search and information extraction. 
                Camtology combines text and image processing to create a unique solution to this problem. 
            </paragraph> 
        </section> 
        <section> 
            <title>2 Status</title> 
            <paragraph> 
                Camtology has developed a search and information extraction system which is currently undergoing usability testing with the curation team for FlyBase, a $1m/year NIH-funded curated database covering the functional genomics of the fruit fly. 
                To provide a scalable solution capable of analysing the entire STEM bibliome of over 20m electronic journal and conference papers, we have developed a robust system that can be used with a grid of computers running distributed job management software. 
                http://flybase.org/ 
            </paragraph> 
            <paragraph> 
                <context>
                    <author>This</author> 
                    <tool>system</tool> 
                    <kw>has been deployed and tested</kw> 
                    <kw>using a subset of</kw> the resources provided by the <data>UK Grid for Particle Physics</data> (<cite id="1" function="bas" polarity="pos">Britton et al., 2009</cite>)
                </context>
                , part of the worldwide Grid of around 200000 CPU cores assembled to allow analysis of the petabyte-scale data volumes to be recorded each year by experiments at the Large Hadron Collider in Geneva. 
                Processing of the FlyBase archive of around 15000 papers required about 8000 hours of CPU time, and has been successfully completed in about 3 days, with up to a few hundred jobs run in parallel. 
                A distributed spider for collecting open-source PDF documents has also been developed. 
                This has been run concurrently on over 2000 cores cores, and has been used to retrieve over 350000 subject-specific papers, but these are not considered in the present demo. 
            </paragraph> 
        </section> 
        <section imrad="m"> 
            <title>3 Functionality</title> 
            <paragraph> 
                Camtology's search and extraction engine is the first to integrate a full structural analysis of a scientific paper in PDF format (identifying headings, sections, captions and associated figures, citations and references) with a sentence-by-sentence grammatical analysis of the text and direct visual search over figures. 
                Combining these capabilities allows us to transform paper search from keyword based paper retrieval, where the end result is a set of putatively relevant PDF files which need to be read, to information extraction based on the ability to interactively specify a rich variety of linguistic patterns which return sentences in specific document locales, and which combine text with image-based constraints; for instance: 
                "all sentences in figure captions which contain any gene name as the theme of the action 'express' where the figure is a picture of an eye" 
            </paragraph> 
            <paragraph> 
                Camtology allows the user to build up such complex queries quickly though an intuitive process of query refinement. 
            </paragraph> 
            <paragraph> 
                Figures often convey information crucial to the understanding of the content of a paper and are typically not available to search. 
                Camtology's search engine integrates text search to the figure and caption level with the ability to re-rank search returns on the basis of visual similarity to a chosen archetype (ambiguities in textual relevance are often resolved by visual appearance). 
                Figure 1 provides a compact overview of the search functionality supported by our current demonstrator. 
                Interactively, constructing and running such complex queries takes a few seconds in our intuitive user interface, and allows the user to quickly browse and then aggregate information across the entire collection of papers indexed by the system. 
                For instance, saving the search result from the example above would yield a computer-readable list of gene names involved in eye development (in fruit flies in our demonstrator) in a second or so. 
                With existing web portals and keyword based selection of PDF files (for example, Google Scholar, ScienceDirect, DeepDyve or PubGet), a query like this would typically take many hours to open and read each one, using cut and paste to extract gene names (and excludes the possibility of ordering results on a visual basis). 
                The only other alternative would require expensive bespoke adaptation of a text mining system by IT professionals using licensed software (such as Ariadne Genomics, Temis or Linguamatics). 
                This option is only available to a tiny minority of researchers working for large well-funded corporations. 
            </paragraph> 
        </section>
        <section imrad="r">
            <title>4 Summary of Technology</title> 
            <subsection> 
                <subtitle>4.1 PDF to SciXML</subtitle> 
                <paragraph> 
                    The PDF format represents a document in a manner designed to facilitate printing. 
                    In short, it provides information on font and position for textual and graphical units. 
                    To enable information retrieval and extraction, we need to convert this typographic representation into a logical one that reflects the structure of scientific documents. 
                    <context>
                        <author>We</author> 
                        <kw>use an</kw> 
                        <method>XML schema</method> called SciXML (first introduced in <cite id="2" function="bas" polarity="pos">Teufel et al. (1999)</cite>) that we extend to include images. 
                    </context>
                    We linearise the textual elements in the PDF, representing these as &lt;div&gt; elements in XML and classify these divisions as {Title \! Author \! Affiliation \! Abstract \! Footnote \! Caption \! 
                    Heading \! Citation \! References \! Text} in a constraint satisfaction framework. 
                </paragraph> 
                <paragraph> 
                    In addition, we identify all graphics in the PDF, including lines and images. 
                    We then identify tables by looking for specific patterns of text and lines. 
                    A bounding box is identified for a table and an image is generated that overlays the text on the lines. 
                    Similarly we overlay text onto images that have been identified and identify bounding boxes for figures. 
                    This representation allows us to retrieve figures and tables that consist of text and graphics. 
                    Once bounding boxes for tables or figures have been identified, we identify a one-to-one association between captions and boxes that minimises the total distance between captions and their associated figures or tables. 
                    The image is then referenced from the caption using a "SRC" attribute; for example, in (abbreviated for space constraints): 
                    <CAPTION SRC= "FBrf0174566_fig_6_o.png"> 
                        <b>Fig. 
                            6. 
                        </b> Phenotypic analysis of denticle belt fusions during embryogenesis. 
                        (A) The denticle belt fusion phe-notype resulted in folds around ...the only cuticle phenotype of the DN-EGFR-expressing embryos was strong denticle belt fusions in alternating parasegments (<i>paired </i>domains). 
                    </CAPTION> 
                    Note how informative the caption is, and the value of being able to search this caption in conjunction with the corresponding image (also shown above). 
                </paragraph> 
            </subsection> 
            <subsection> 
                <subtitle>4.2 Natural Language Processing</subtitle> 
                <paragraph> 
                    Every sentence, including those in abstracts, titles and captions, is run through our named-entity recog-niser and syntactic parser. 
                    The output of these systems is then indexed, enabling semantic search. 
                </paragraph>
                <subsection> 
                    <subtitle>Named Entity Recognition</subtitle> 
                    <paragraph> 
                        <context>
                            <method>NER</method> in the biomedical domain <kw>was implemented</kw> 
                            <kw>as described in</kw> 
                            <cite id="3" function="use" polarity="neu">Vlachos (2007)</cite>. 
                        </context>
                        Gene Mention tagging was performed using Conditional Random Fields and syntactic parsing, using features derived from grammatical relations to augment the tagging. 
                        We also use a probabilistic model for resolution of non-pronominal anaphora in biomedical texts. 
                        <context>
                            The model focuses on biomedical entities and seeks to find the antecedents of anaphora, both coreferent and associative ones, and also to identify discourse-new expressions (<cite id="4" function="ack" polarity="neu">Gasperin and Briscoe, 2008</cite>). 
                        </context>
                        for sentence boundary detection, tokenisation, PoS tagging and finding grammatical relations (GR) between words in the text. 
                        GRs are triplets consisting of a relation-type and two arguments and also encode morphology, word position and part-of-speech; for example, parsing "John likes Mary." gives us a subject relation and a direct object relation: (\!ncsubj\! \!like+s:2_VVZ\! \!John:1_NP1\!) (\!dobj\! \!like+s:2_VVZ\! \!Mary:3_NP1\!) 
                        Representing a parse as a set of flat triplets allows us to index on grammatical relations, thus enabling complex relational queries. 
                    </paragraph> 
                </subsection> 
            </subsection> 
            <subsection> 
                <subtitle>4.3 Image Processing</subtitle> 
                <paragraph> 
                    We build a low-dimensional feature vector to summarise the content of each extracted image. 
                    <context>
                        Colour and intensity histograms are encoded in a short bit string which describes the image globally; this is concatenated with a description of the image derived from a wavelet decomposition (<cite id="5" function="ack" polarity="neu">Jacobs et al., 1995</cite>) that captures finer-scale edge information. 
                    </context>
                    <context>
                        Efficient similar image search is achieved by projecting these feature vectors onto a small number of randomly-generated hyperplanes and using the signs of the projections as a key for locality-sensitive hashing (<cite id="6" function="ack" polarity="neu">Gionis et al., 1999</cite>). 
                    </context>
                </paragraph> 
            </subsection> 
            <subsection> 
                <subtitle>4.4 Indexing and Search</subtitle> 
                <paragraph> 
                    <context>
                        <author>We</author> 
                        <kw>use</kw> 
                        <tool>Lucene</tool> (<cite id="7" function="bas" polarity="pos">Goetz, 2002</cite>) for indexing and retrieving sentences and images. 
                    </context>
                    Lucene is an open source indexing and information retrieval library that has been shown to scale up efficiently and handle large numbers of queries. 
                    We index using fields derived from word-lemmas, grammatical relations and named entities. 
                    At the same time, these complex representations are hidden from the user, who, as a first step, performs a simple keyword search; for example "express Vnd". 
                    This returns all sentences that contain the words "express" and "Vnd" (search is on lemmatised words, so morphological variants of "express" will be retrieved). 
                    Different colours represent different types of biological entities and processes (green for a gene), and blue shows the entered search terms in the result sentences. 
                    An example sentence retrieved for the above query follows: It is possible that like ac , sc and l'sc , vnd is expressed initially in cell clusters and then restricted to single cells. 
                </paragraph> 
                <paragraph> 
                    Next, the user can select specific words in the returned sentences to indirectly specify a relation. 
                    Clicking on a word will select it, indicated by underlining of the word. 
                    In the example above, the words "vnd" and "expressed" have been selected by the user. 
                    This creates a new query that returns sentences where "vnd" is the subject of "express" and the clause is in passive voice. 
                    This retrieval is based on a sophisticated grammatical analysis of the text, and can retrieve sentences where the words in the relation are far apart. 
                    An example of a sentence retrieved for the refined query is shown below: 
                    First, vnd might be spatially regulated in a manner similar to ac and sc and selectively expressed in these clusters . 
                </paragraph> 
                <paragraph> 
                    Camtology offers two other functionalities. 
                    The user can browse the MeSH (Medical Subject Headings) ontology and retrieve papers relevant to a MeSH term. 
                    Also, for both search and MeSH browsing, retrieved papers are plotted on a world map; this is done by converting the affiliations of the authors into geospatial coordinates. 
                    The user can then directly access papers from a particular site. 
                </paragraph> 
            </subsection> 
        </section> 
 
        <section imrad="d"> 
            <title>5 Script Outline</title> 
            <paragraph> 
                I Quick overview of existing means of searching science (PubMed, FlyBase, Google Scholar). 
            </paragraph> 
            <paragraph> 
                II Walk through the functionality of Camtology (these are numbered in Figure 1: 
                • (1) Initial query through textual search box; (2) Retrieval of relevant sentences; (3) Query refinement by clicking on words; (4) Using implicit grammatical relations for new search; 
                • Alternative to search: (5) Browse MeSH Ontology to retrieve papers with MeSH terms. 
                • (6) Specifically searching for tables/figures 
                • (7) Viewing the affiliation of the authors of retrieved papers on a world map. 
                • (8) Image search using similarity of image. 
            </paragraph> 
        
            <title>6 Acknowledgements</title> 
            <paragraph> 
                This work was supported in part by a STFC miniP-IPSS grant to the University of Cambridge and iLexIR Ltd. 
            </paragraph> 
        </section> 
    </paper>
</annotatedpaper>