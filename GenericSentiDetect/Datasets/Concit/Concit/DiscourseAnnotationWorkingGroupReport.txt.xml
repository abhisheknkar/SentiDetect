<annotatedpaper><paper title="Discourse Annotation Working Group Report" authors="Manfred Stede, Janyce Wiebe, Eva Hajicov ˇ a, Brian Reese, Simone Teufel, Bonnie Webber, Theresa Wilson" year="2007"> 
<section> 
<title>Discourse Annotation Working Group Report</title> 
Manfred Stede 
Dept. of Linguistics 
University of Potsdam 
stede@ling.uni-potsdam.de 
Janyce Wiebe 
Dept. of Computer Science 
University of Pittsburgh 
wiebe@cs.pitt.edu 
Eva Hajicov ˇ a´ 
Faculty of Math. and Physics 
Charles University 
hajicova@ufal.ms.mff.cuni.cz 
Brian Reese 
Dept. of Linguistics 
Univ. of Texas at Austin 
bjreese@mail.utexas.edu 
Simone Teufel 
Computer Laboratory 
Univ. of Cambridge 
sht25@cl.cam.uk 
Bonnie Webber 
School of Informatics 
Univ. of Edinburgh 
bonnie@inf.ed.ac.uk 
Theresa Wilson 
Dept. of Comp. Science 
Univ. of Pittsburgh 
twilson@cs.pitt.edu 
</section> 
<section imrad="i"> 
<title>1. Introduction</title> 
<paragraph> 
can be studied systematically. This conception of multi-level annotation presupposes, of course, that the technical problems of setting annotation levels in correspondence to one another be resolved. 
</paragraph> 
<paragraph> 
The panel on discourse annotation is organized by Manfred Stede and Janyce Wiebe. It aims at surveying the scene of discourse corpora, exploring chances for synergy, and identifying desiderata for future corpus creation projects. In preparation for the panel, the participants have provided the following short descriptions ofthe various copora in whose construction they have been involved.  
</paragraph> 
</section> 
<section imrad="m"> 
<title>2 Prague Dependency Treebank (Eva HajiCova, Prague)</title> 
<paragraph> 
One of the maxims of the work on the Prague Dependency Treebank is that one should not overlook, disregard and thus lose what the sentence structure offers when one attempts to analyze the structure of discourse, thus moving from "the trees" to "the forest". Therefore, we emphasize that discourse annotation should make use of every possible detail the annotation of the component parts of the discourse, namely the sentences, puts at our disposal. This is, of course, not only true for the surface shape of the sentence (i.e., the surface means of expression), but (and most importantly) for the underlying representation of sentences. The panel contribution will introduce the (multilayered) annotation scenario of the Prague Dependency Treebank and illustrate the point using some ofthe particular features ofthe underlying structure of sentences that can be made use of in planning the scenario of discourse 'treebanks'.  
</paragraph> 
</section> 
<section imrad="m"> 
<title>3 SDRT in Newspaper Text (Brian Reese, Austin)</title> 
<paragraph> 
We are currently working under the auspices of an NSF grant to build and train a discourse parser and codependent anaphora resolution program to test discourse theories empirically. The training requires the construction of a corpus annotated with discourse structure and coreference information. So far, we have annotated the MUC6 corpus for discourse structure and are in the process of annotating the ACE2 corpus; both corpora are already annotated for coreference. One ofthe goals ofthe project is to investigate whether using the right frontier constraint improves the system's performance in resolving anaphors. Here we detail some experiences we have had with the discourse annotation process.  
</paragraph> 
<paragraph> 
<context>An <kw>implementation of</kw> the extant sdrt (<cite id="1" function="wea" polarity="neg">Asher and Lascarides, 2003</cite>) glue logic for building discourse structures <negfeature>is insufficient to</negfeature> deal with open domain text,</context> and we cannot envision an extended version at the present time able to deal with the problem. Thus, we have opted for a machine learning based approach to discourse parsing based on superficial features, like BNL. To build an implementation to test these ideas, we have had to devise a corpus of texts annotated for discourse structure in SDRT. 
 </paragraph> 
<paragraph> 
Each of the 60 texts in the MUC6 corpus, and now 18 of the news stories in ACE2, were annotated by two people familiar with sdrt. The annotators then conferred and agreed upon a gold standard. Our annotation effort took the hierarchical structure of SDRT seriously and built graphs in which the nodes are discourse units and the arcs represent discourse relations between the units. The units could either be simple (elementary discourse units: EDUs) or they could be complex. We assumed that in principle the units were recursively generated and could have an arbitrary though finite degree of complexity.  
</paragraph> 
</section> 
<section imrad="m"> 
<title>4 Potsdam Commentary Corpus (Manfred Stede, Potsdam)</title> 
<paragraph> 
Construction of the Potsdam Commentary Corpus (PCC) began in 2003 and is still ongoing. It is a genre-specific corpus of German newspaper commentaries, taken from the daily papers Markische Allgemeine Zeitung and Tagesspiegel. One central aim is to provide a tool for studying mechanisms of argumentation and how they are reflected on the linguistic surface. The corpus on the one hand is a collection of "raw" data, which is used for genre-oriented statistical explorations. On the other hand, we have identified two sub-corpora that are subject to a rich multi-level annotation (MLA). The Message Understanding Conference, www-nlpir. nist. gov/relatecLproj ects/muc/. The Automated Content Extraction program, www.nist.gov/speech/tests/ace/ .  
</paragraph> 
<paragraph> 
    <context>The PCC176 (<cite id="2" function="use" polarity="neu">Stede, 2004</cite>) is a <data>sub-corpus</data> that <kw>is available upon</kw> request <kw>for</kw> research purposes.</context> It consists of 176 relatively short commentaries (1215 sentences), with 33.000 tokens in total. The sentences have been PoS-tagged automatically (and manually checked); <context>sentence syntax was annotated semi-automatically using the TIGER scheme (<cite id="3" function="ack" polarity="neu">Brants et al., 2002</cite>) and Annotate tool.</context> 
    <context>In addition, <author>we</author> 
        <kw>annotated</kw> coreference (PoCos (<cite id="4" function="bas" polarity="pos">Krasavina and Chiarcos, 2007</cite>)) and rhetorical structure <kw>according to</kw> RST (<cite id="5" function="bas" polarity="pos">Mann and Thompson, 1988</cite>).</context> Our annotation software architecture consists of a variety of standard, external tools that can be used effectively for the different annotation types. <context>Their <data>XML output</data> 
        is then automatically <kw>converted to</kw> a generic format (PAULA, (<cite id="6" function="use" polarity="neu">Dipper, 2005</cite>)), <kw>which is read into</kw> the linguistic database ANNIS (<cite id="7" function="use" polarity="pos">Dipper et al., 2004</cite>), where the annotations are aligned, <kw>so that</kw> the data <kw>can be viewed</kw> and queried across annotation levels.</context>  
</paragraph> 
<paragraph> 
    The PCC10 is a sub-corpus of 10 commentaries that serves as "testbed" for further developing the annotation levels. <context>On the one hand, <author>we</author> 
        <kw>are applying</kw> 
        <posfeature>recent</posfeature> guidelines on annotation of information structure (<cite id="8" function="bas" polarity="pos">Gotze et al., 2007</cite>)</context>. <context>On the other hand, based on experiences with the RST annotation, <author>we</author> 
        <kw>are replacing</kw> the rhetorical trees <kw>with a set of</kw> distinct, <kw>simpler</kw> annotation layers: thematic structure, conjunctive relations (<cite id="9" function="bas" polarity="pos">Martin, 1992</cite>), and argumentation structure (<cite id="10" function="bas" polarity="pos">Freeman, 1991</cite>);</context> these are complemented by the other levels mentioned above for the PCC176. <context>The primary motivation for this step is the high degree of arbitrariness that annotators reported when producing the RST trees (see (<cite id="11" function="ack" polarity="neu">Stede, 2007</cite>))</context>. By separating the thematic from the intentional information, and accounting for the surface-oriented conjunctive relations (which are similar to what is annotated in the PDTB, see Section 6), we hope to www.coli.uni-saarland.de/projects/ sfb3 7 8/negra-corpus/annotate.html  
</paragraph> 
<paragraph> 
• make annotation easier: handling several "simple" levels individually should be more effective than a single, very complex annotation step; 
</paragraph> 
<paragraph> 
• end up with less ambiguity in the annotations, since the reasons for specific decisions can be made explicit (by annotations on "simpler" levels); 
</paragraph> 
<paragraph> 
• be more explicit than a single tree can be: if a discourse fulfills, for example, a function both for thematic development and for the writer's intention, they can both be accounted for; 
</paragraph> 
<paragraph> 
• provide the central information that a "traditional" rhetorical tree conveys, without loosing essential information. 
</paragraph> 
</section> 
<section imrad="m"> 
<title>5 AZ Corpus</title> 
<paragraph> 
    (Simone Teufel, Cambridge) <context>The Argumentative Zoning (AZ) <method>annotation scheme</method> (<cite id="12" function="use" polarity="neu">Teufel, 2000</cite>; <cite id="13" function="use" polarity="neu">Teufel and Moens, 2002</cite>) <kw>is concerned with</kw> 
        <task>marking argumentation steps</task> 
        <kw>in</kw> scientific articles.</context> One example for an argumentation step is the description of the research goal, another an overt comparison of the authors' work with rival approaches. In our scheme, these argumentation steps have to be associated with text spans (sentences or sequences of sentences). <context>AZ-Annotation is the labelling of each sentence in the text with one of these labels (7 in the original scheme in (<cite id="14" function="ack" polarity="neu">Teufel, 2000</cite>)).</context> The AZ labels are seen as relations holding between the meanings of these spans, and the rhetorical act of the entire paper. <context>(<cite id="15" function="ack" polarity="neu">Teufel et al., 1999</cite>) reports on interannotator agreement studies with this scheme.</context> 
 </paragraph> 
<paragraph> 
    There is a strong interrelationship between the argumentation in a paper, and the citations writers use to support their argument. <context>Therefore, a part of the computational linguistics <data>corpus</data> 
        <kw>has</kw> a second <kw>layer of</kw> annotation, called CFC (<cite id="16" function="use" polarity="neu">Teufel et al., 2006</cite>) or <task>Citation Function Classification</task>. CFC- annotation <kw>records for</kw> each citation which rhetorical function it plays in the argument.</context>
    <context> 
        <kw>This is</kw> 
        <posfeature>following the spirit of</posfeature> 
        <kw>research in</kw> 
        <task>citation content analysis</task> (<kw>e.g.</kw>, (<cite id="17" function="ack" polarity="pos">Moravcsik and Murugesan, 1975</cite>))</context>. An example for a citation function would be "motivate that the method used is sound". The annotation scheme contains 12 functions, clustered into "superiority", "neutral comparison/contrast", "praise or usage" and "neutral".  
</paragraph> 
<paragraph> 
One type of research we hope to do in the future is to study the relationship between these rhetorical phonemena with more traditional discourse phenomena, e.g. anaphoric expressions. 
</paragraph> 
<paragraph> 
The CmpLg/ACL Anthology corpora consist of 320/9000 papers in computational linguistics. They are partially annotated with AZ and CFC markup. A subcorpus of80 parallelly annotated papers (AZ and CFF) can be obtained from us for research (12000 sentences, 1756 citations). We are currently porting both schemes to chemistry in the framework of the EPSRC-sponsored project SciBorg. In the course of this work a larger, more general AZ annotation scheme was developed. The SciBorg effort will result in an AZ/CFC-annotated chemistry corpus available to the community in 2009.  
</paragraph> 
<paragraph> 
In terms of challenges, the most time-consuming aspects of creating this annotated corpus were format conversions on the corpora, and cyclic adaptations of scheme and guidelines. 
Another problem is the simplification of annotating only full sentences; sometimes, annotators would rather mark a clause or sometimes even just an NP. 
However, we found these cases to be relatively rare. 
</paragraph> 
</section> 
<section imrad="r"> 
<title>6 Penn Discourse Treebank (Bonnie Webber, Edinburgh)</title> 
<paragraph> 
    <context>The <data>Penn Discourse TreeBank</data> (<cite id="18" function="use" polarity="neu">Miltsakaki et al., 2004</cite>; <cite id="19" function="use" polarity="neu">Prasad et al., 2004</cite>; <cite id="20" function="use" polarity="neu">Webber, 2005</cite>) <action>annotates</action> discourse <kw>relations over</kw> the Wall Street Journal <data>corpus</data> (<cite id="21" function="use" polarity="neu">Marcus et al., 1993</cite>), in terms of discourse connectives and their arguments.</context> 
    <context>
        <kw>Following</kw> the <kw>approach towards</kw> discourse structure <kw>in</kw> (<cite id="22" function="use" polarity="neu">Webber et al., 2003</cite>), the PDTB <kw>takes a</kw> 
        <method>lexicalized approach</method>, <kw>treating</kw> discourse connectives <kw>as</kw> the anchors of the relations and thus as discourse-level predicates taking two Abstract Objects as their arguments.</context> Annotated are the text spans that give rise to these arguments. There are primarily two types of connectives in the PDTB: explicit and implicit, the latter being inserted between adjacent paragraph-internal sentence pairs not related by an explicit connective. <context>Also annotated in the PDTB is the attribution of each discourse relation and of its arguments (<cite id="23" function="ack" polarity="neu">Dinesh et al., 2005</cite>; <cite id="24" function="ack" polarity="neu">Prasad et al., 2007</cite>).</context> (Attribution itself is not considered a discourse relation.) <context>
        <kw>A preliminary version of</kw> the PDTB <kw>was released in</kw> April 2006 (<cite id="25" function="use" polarity="neu">PDTB-Group, 2006</cite>), and <kw>is available for</kw> 
        <kw>download at</kw> http://www.seas.upenn.edu/~pdtb.</context> This release only has implicit connectives annotated in three sections of the corpus. <context>The annotation of all implicit connectives, along with a hierarchical semantic classification of all connectives (<cite id="26" function="ack" polarity="neu">Miltsakaki et al., 2005</cite>), will appear in the final release of the PDTB in August 2007.</context>  
</paragraph> 
<paragraph> 
Here I want to mention three of the challenges we have faced in developing the PDTB: 
</paragraph> 
<paragraph> 
(I) Words and phrases that can function as connectives can also serve other roles. (Eg, when can be a relative pronoun, as well as a subordinating conjunction.) <context>It <kw>has been</kw> <negfeature>difficult to</negfeature> identify all and only those cases where a token functions as a discourse connective, and <kw>in many cases</kw>, the syntactic analysis in the <data>Penn TreeBank</data> (<cite id="27" function="wea" polarity="neg">Marcus et al., 1993</cite>) <negfeature>provides no help</negfeature>.</context> For example, is as though always a subordinating conjunction (and hence a connective) or do some tokens simply head a manner adverbial (eg, seems as though ... versus seems more rushed as though ...)? Is also sometimes a discourse connective relating two abstract objects and other times, an adverb that presupposes that a particular property holds of some other entity? If so, when one and when the other? In the PDTB, annotation has erred on the side of false positives. 
 </paragraph>  
<paragraph> 
(II) In annotating implicit connectives, we discovered systematic non-lexical indicators of discourse relations. In English, these include cases of marked syntax (eg, Had I known the Queen would be here, I would have dressed better.) and cases of sentence-initial PPs and adjuncts with anaphoric or deictic NPs such as at the other end of the spectrum, adding to that speculation. These cases labelled ALTLEX, for "alternative lexicalisation" have not been annotated as connectives in the PDTB because they are fully productive (ie, not members of a more easily annotated closed set of tokens). They comprise about 1% of the cases the annotators have considered. Future discourse annotation will benefit from further specifying the types of these cases. 
 </paragraph> 
<paragraph> 
(III) <context><kw>The way in which</kw> spans are annotated as arguments to connectives <negfeature>also raises a challenge</negfeature>. First, because the PDTB annotates both structural and anaphoric connectives (<cite id="28" function="wea" polarity="neg">Webber et al., 2003</cite>), a span can serve as argument to >1 connective. Secondly, unlike in the RST corpus (<cite id="29" function="wea" polarity="neg">Carlson et al., 2003</cite>) or the Discourse GraphBank (<cite id="30" function="wea" polarity="neg">Wolf and Gibson, 2005</cite>), discourse segments <negfeature>are not separately annotated</negfeature>, with annotators then identifying what discourse relations hold between them.</context> Instead, in annotating arguments, PDTB annotators have selected the minimal clausal text span needed to interpret the relation. This could comprise an embedded, subordinate or coordinate clause, an entire sentence, or a (possibly disjoint) sequence of sentences. As a result, there are fairly complex patterns ofspans within and across sentences that serve as arguments to different connectives, and there are parts of sentences that don't appear within the span of any connective, explicit or implicit. The result is that the PDTB provides only a partial but complexly-patterned cover of the corpus. <context><kw>Understanding what's going on</kw> and <kw>what it implies for</kw> discourse structure (and possibly syntactic structure as well) is a challenge <author>we're</author> currently <kw>trying to</kw> address (<cite id="31" function="bas" polarity="pos">Lee et al., 2006</cite>).</context>  
</paragraph> 
</section> 
<section imrad="d"> 
<title>7 MPQA Opinion Corpus (Theresa Wilson, Pittsburgh)</title> 
<paragraph> 
<context><author>Our</author> <tool>opinion annotation scheme</tool> (<cite id="32" function="bas" polarity="pos">Wiebe et al., 2005</cite>) <kw>is centered on</kw> the notion of private state, a general term that covers opinions, beliefs, thoughts, sentiments, emotions, intentions and evaluations. <kw>As</kw> <cite id="33" function="bas" polarity="pos">Quirk et al. (1985)</cite> <kw>define it</kw>, a private state is a state that is not open to objective observation or verification.</context> We can further view private states in terms of their functional components — as states of experiences holding attitudes, optionally toward targets. For example, for the private state expressed in the sentence John hates Mary, the experiencer is John, the attitude is hate, and the target is Mary. We create private state frames for three main types of private state expressions (subjective expressions) in text:  
</paragraph> 
<paragraph> 
• explicit mentions of private states, such as "fears" in "The U.S. fears a spill-over" 
</paragraph> 
<paragraph> 
• speech events expressing private states, such as "said" in "The report is full of absurdities," 
Xirao-Nima said. 
</paragraph> 
<paragraph> 
• expressive subjective elements, such as "full of absurdities" in the sentence just above. Frames include the source (experiencer) of the private state, the target, and various properties such as polarity (positive, negative, or neutral) and intensity (high, medium, or low). Sources are nested. 
 </paragraph> 
<paragraph> 
For example, for the sentence "China criticized the U.S. report's criticism of China's human rights record", the source is {writer, China, U.S. report), reflecting the facts that the writer wrote the sentence and the U.S. report's criticism is the target of China's criticism. It is common for multiple frames to be created for a single clause, reflecting various levels of nesting and the type of subjective expression.  
</paragraph> 
<paragraph> 
<context>The <method>annotation scheme</method> <kw>has been applied to</kw> a corpus, called the "Multi-Perspective Question Answering (MPQA) Corpus," reflecting its origins in the 2002 NRRC Workshop on Multi-Perspective Question Answering (MPQA) (<cite id="34" function="use" polarity="neu">Wiebe et al., 2003</cite>) sponsored by ARDA AQUAINT (it is also called "OpinionBank"). It contains 535 documents and a total of 11,114 sentences. The articles in the corpus are from 187 different foreign and U.S. news sources, dating from June 2001 to May 2002. <kw>Please see</kw> (<cite id="35" function="use" polarity="neu">Wiebe et al., 2005</cite>) and Theresa Wilson's forthcoming PhD dissertation <kw>for further information</kw>, including the results of inter-coder agreement studies.</context>  
</paragraph> 
</section> 
</paper> 
</annotatedpaper>