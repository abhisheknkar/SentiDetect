<annotatedpaper>
    <paper title= "A Hierarchical Classifier Applied to Multi-way Sentiment Detection" year="2010" authors="Adrian Bickerstaffe and Ingrid Zukerman">
        <section>
            <title>A Hierarchical Classifier Applied to Multi-way Sentiment Detection</title>
            Adrian Bickerstaffe and Ingrid Zukerman
            Faculty of Information Technology
            Monash University
            bickerstaffe.adrian@gmail.com,Ingrid.Zukerman@monash.edu
        </section>
        <section>
            <title>Abstract</title>
            <paragraph>This paper considers the problem of document-level multi-way sentiment detection, proposing a hierarchical classifier algorithm that accounts for the inter-class similarity of tagged sentiment-bearing texts. This type of classifier also provides a natural mechanism for reducing the feature space of the problem. Our results show that this approach improves on state-of-the-art predictive performance for movie reviews with three-star and four-star ratings, while simultaneously reducing training times and memory requirements.</paragraph>
        </section>
        <section imrad="i">
            <title>1 Introduction</title>
           
                <paragraph> <context>A key problem in sentiment detection is to determine the polarity of sentiment in text. Much of the work on this problem has considered binary sentiment polarity (positive or negative) at granularity levels ranging from sentences  <cite id="1" function="ack" polarity="neu">(Yu and Hatzivas-siloglou, 2003; Mao and Lebanon, 2006</cite>; <cite id="2" function="ack" polarity="neu">McDonald et al., 2007</cite>) to documents (<cite id="3" function="ack" polarity="neu">Wilson et al., 2005</cite>; <cite id="4" function="ack" polarity="neu">Allison, 2008</cite>)</context>.</paragraph>
            
            <paragraph>This paper considers the more general problem of multi-way sentiment classification for discrete, ordinal rating scales, focusing on the document level, i.e., the problem of predicting the "star" rating associated with a review. This is a supervised learning task involving textual reviews that have been tagged with a rating. Ultimately, the goal is to use classifiers which have been trained on tagged datasets to predict the ratings of untagged reviews.</paragraph>
            <paragraph>
                
                <context>
                    <kw>Typical</kw> 
                    <method>approaches</method> 
                    to
                    <task>the rating scale problem</task> 
                    <kw>include</kw> standard <tool>k-way classifiers</tool>, e.g., (<cite id="5" function="use" polarity="pos">Pang and Lee, 2005</cite>).
                </context>

                However, these methods do not explicitly account for sample similarities, e.g., the samples with a "four star" rating being more similar to "three star" samples than to "one star" samples. 
                
               <context>    These methods generally, do not perform well, while methods which incorporate sample similariity information achieve<posfeature> improved performance</posfeature>. <cite id="6" function="ack" polarity="pos">Pang and Lee, 2005</cite>
                </context>
            
            </paragraph>
            <paragraph>
                <context>
                    <task>Sample similarity</task> in the multi-way sentiment detection setting <kw>has previously been considered</kw> 
                    <kw>by using</kw> 
                    <method>Support Vector Machines (SVMs)</method> in conjunction with a metric labeling meta-algorithm (<cite id="7" function="use" polarity="neu">Pang and Lee, 2005</cite>);
                </context>
                <context>
                    <kw>by taking</kw> a <method>semi-supervised graph-based learning approach</method> (<cite id="8" function="wea" polarity="neg">Goldberg and Zhu, 2006</cite>); <kw>and by using</kw> 
                    <method>"optimal stacks" of SVMs</method> (<cite id="9" function="wea" polarity="neg">Koppel and Schler, 2006</cite>). <kw>However</kw>, <negfeature>each of these methods have shortcomings</negfeature> (Section 2). 
                </context>
                Additionally, during the learning process, all approaches employ a set of word/punctuation features collected across all rating categories. Hence, the number of features may be very large compared to the number of training samples, which can lead to the model overfitting the data.</paragraph>
            <paragraph>The main contribution of this paper is the use of hierarchical classifier trees which combine standard binary classifiers to perform multi-way classification 
                <context>
                    (another
                    <method>approach</method> 
                    <kw>to reduce</kw> 
                    <task>multi-class classification to binary classifications</task> 
                    <kw>is described in</kw> (<cite id="10" function="use" polarity="neu">Beygelzimer et al., 2009</cite>))
            
                </context>
                . The hierarchical classifier accounts for inter-class similarity by means of tree structures which are obtained using inter-class similarity measures in conjunction with a shortest-spanning algorithm. The tree structures reduce training times since they require only k — 1 nodes for a k-rating problem. Training times are further reduced by the fact that classifier nodes lower in the tree consider fewer rating classes than those higher up, thereby naturally reducing the number of training samples relevant to lower-level nodes. Additionally, the tree structures offer a means to safely cull irrelevant features at non-root nodes of the tree, thus reducing the dimensionality of the training data for these nodes without loss of information. Our experiments show that our new classifier outperforms state-of-the-art methods on average, achieving improvements of up to 7.00% and 7.72% for three-way and four-way classification problems respectively (Section 4).</paragraph>
        </section>
        <section imrad="m">
            <title>2 Related Work</title>
            
            <paragraph>
                
                <context>Pang and <cite id="11" function="ack" polarity="neu">Lee (2005)</cite> incorporated information about label similarities using metric labeling, where label relations were encoded via a distance metric. 
                </context>
                The output of standard k-ary classifiers was then modified such that similar items were more likely to be assigned similar labels. Metric labeling required a label-corrected item-similarity function, which was based on the observation that the Percentage of Positive Sentences (PSP) in reviews increased as their ratings increased. Notice, however, that item similarity was not incorporated into the first stage of classifier training. Metric labeling adjusted the output of the classifiers only after they were trained without considering rating similarities. Our approach accounts for inter-category relationships from the outset of classifier design, rather than addressing this issue with later adjustments.</paragraph>
            <paragraph> 
                <context>
                    <cite id="12" function="ack" polarity="neu">Goldberg and Zhu (2006)</cite> proposed a semi-supervised learning approach to the rating inference problem in scenarios where labeled training data is scarce.
                </context>
                Using a graph-based optimisation approach, Goldberg and Zhu demonstrated that the inclusion of unlabeled reviews in the learning process could produce significantly higher prediction accuracy than predictors trained without unlabeled data.       <context>
                    <method>This approach</method> <posfeature>outperformed competing methods</posfeature> when it considered relatively small numbers of labeled samples from the four-category movie review dataset (<cite id="13" function="ack" polarity="pos">Pang and Lee, 2005</cite>). 
                </context>
                However, the graph-based method did not perform well when a large number of labeled samples was available. Furthermore, Goldberg and Zhu's graph-based learning method was transductive: new samples could not be classified until they were added to the graph — a problem avoided by our approach.
            
            </paragraph>
            <paragraph>
                <context>
                    <cite id="14" function="ack" polarity="neu">Koppel and Schler (2006)</cite> considered neutral examples, which may express a mixed opinion or may not express any opinion at all, in addition to positive/negative samples.
                </context>                
                

                Their experiments showed that neutral examples often did not lie close to the positive/negative decision boundary as previously believed. This gave rise to the idea of "optimal stacks" of SVMs, which were pair-wise combinations of binary classifiers that distinguish between two categories for the ternary positive/neutral/negative problem (instead of a single binary classifier trained using only positive and negative samples). The search for an optimal stack is exponential in time. Hence, finding suitable stacks is feasible for the ternary problem, but becomes intractable for larger numbers of categories (in the general case).</paragraph>
            <paragraph> 
                <context>
                    <cite id="15" function="use" polarity="pos">Snyder and Barzilay (2007)</cite> 
                    <kw>proposed</kw> the <method>"Good Grief" algorithm</method>, which
                    <posfeature>considers multiple aspects of a situation</posfeature> (e.g., a restaurant review that covers service, ambiance and food), and yields a prediction that minimises the dissatisfaction (grief) regarding these aspects.
                </context>

                This method significantly outperformed baseline methods and individual classifiers. At present, we do not consider separately different aspects of a review — a task we intend to undertake in the future.</paragraph>
       
            <title>3 Multiclass SVM Classifiers</title>
            <paragraph>Since SVMs are binary classifiers, they are often employed for binary sentiment detection. However, as seen above, it is not straightforward to use SVMs for multi-way classification, particularly when there is inter-class similarity.</paragraph>
            <paragraph>One might initially expect that a hierarchical SVM classifier could be built using pairwise comparisons of adjacent class labels. However, pair-wise comparisons alone do not form a complete classifier, raising the question of how to combine pairwise classifications.
                <context>
                    <method>The standard techniques to</method>
                    <task>build k-way SVM classifiers</task> 
                    are OVA schemes 
                    (<cite id="16" function="use" polarity="neu">Platt et al., 2000</cite>).
                </context>
                An OVA classifier requires k SVMs for a k-category problem, where the ith SVM is trained using all samples from the ith category versus all other samples. A sample is classified by evaluating all k trained SVMs, and the label of the class which maximizes the decision function is chosen. The OVO scheme trains fc(fc—1) classifiers derived from a pairwise comparison of the target categories. A prediction is made by evaluating each SVM and recording "votes" for the favoured category: the class with the most votes is selected as the predicted category. The DAGSVM scheme builds a Directed Acyclic Graph (DAG) where each non-leaf node has an SVM that discriminates between two classes. A DAGSVM is iteratively constructed in a top-down fashion by forming a list of all the class labels, and creating a decision node that discriminates between the first and last element of the list. This decision node yields two child nodes, each of which omits one of the two classes that were compared. Each of these nodes then discriminates between the first and last element in its list of classes, and so on. This process continues for each decision path until only one element remains in the list. A sample is classified by successively making decisions down the graph until a leaf node is reached. Like OVO, DAGSVM schemes require training fc(fc—1) decision nodes.</paragraph>
            <paragraph>All three techniques suffer from long training times — an issue that is exacerbated by large data sets such as our corpus of approximately 5000 movie reviews (Section 4.1). Additional problems associated with these techniques are: (1) there is no bound on the generalisation error of OVA, (2) OVO schemes tend to overfit, and (3) the performance of a DAGSVM relies on the order in which classes are processed. This order is based on the class labels (rather than similarity between samples), and no practical method is known to optimize this order.</paragraph>
            <paragraph>Overfitting also arises when the number of features is very large compared to the number of training samples. In this case, the SVM training process may discover a decision plane that separates the training data well, but performs poorly on unseen test samples. 
                <context>
                    While SVM training algorithms use regularisation to address the overfit-ting problem, research has shown that a careful reduction in feature vector dimensionality can help combat overfitting (<cite id="17" function="ack" polarity="neu">Weston et al., 2003</cite>).
                </context>
            </paragraph>
            <paragraph>A fundamental problem with the above three schemes is that the similarity between samples of nearby classes is not considered. Instead, categories are assumed to be independent.
                <context>
                    <task>This problem</task> 
                    <kw>may be addressed by</kw> considering <method>SVM regression (SVM-R)</method> (<cite id="18" function="use" polarity="neu">Smola and Scholkopf, 1998</cite>), where class labels are assumed to come from a discretisation of a continuous function that maps the feature space to a metric space.
                </context>
                However, SVM-R, like the SVM schemes described here, trains on the entire feature set for all the classes in the dataset. In the case of sentiment detection, where words and punctuation marks are commonly taken as features, the sheer number of features may overwhelm the number of training samples, and lead to the model overfitting the data. SVM-R also poses the question of how to quantise the regressor's output to produce discrete class predictions.</paragraph>
           
                <subtitle>3.1 The MCST-SVM Classifier</subtitle>
                <paragraph>To address the above problems, we build a decision tree of SVMs that reduces the set of possible classes at each decision node, and takes relative class similarity into account during the tree construction process. We construct the decision tree as a Minimum Cost Spanning Tree (MCST), denoted MCST-SVM, based on inter-class similarity measured from feature values (Lorena and de Car-valho, 2005). Each of the decision tree leaves corresponds to a target class, and the interior nodes group classes into disjoint sets. For each internal node in the MCST, an SVM is trained to separate all the samples belonging to classes in its left subtree from those in its right subtree.
                    <context>
                        <author>We </author>  
                        <kw>use</kw>
                        <method>linear SVMs</method>, <posfeature>which have been shown to be effective</posfeature> text classifiers (<cite id="19" function="bas" polarity="pos">Pang et al., 2002</cite>; <cite id="20" function="bas" polarity="pos">Pang and Lee, 2005</cite>), <kw>and set</kw> 
                        <data>the SVM parameters</data> 
                        <kw>to match those used in</kw> (<cite id="21" function="bas" polarity="pos">Pang and Lee, 2005</cite>). 
                    </context>
                
                    Figure 1 contrasts the DAGSVM and MCST-SVM approaches for a four-class example.
                    <context>
                        <method>SVMs</method> 
                        <kw>are implemented using</kw> 
                        <tool>the C/C++ library liblinear</tool>, a variant of libsvm (<cite id="22" function="bas" polarity="pos">Chang and Lin, 2001</cite>).
                    </context>

                    Figure 1: Top section of DAGSVM (left) versus MCST-SVM (right).</paragraph>
                <paragraph>The MCST is constructed using Kruskal's algorithm (1956), which works in polynomial time (Algorithm 1). This algorithm requires a measure of the similarity between every pair of classes, which is calculated using the distance between a representative vector for each class (Section 3.2). The MCST is iteratively built in a bottom-up fashion, beginning with all classes as singleton nodes. In each iteration, the algorithm constructs a node comprising the most similar sets of classes from two previously generated nodes. The similarity between two sets of classes is the shortest distance between the representative vectors of the classes in each set. For instance, the shortest distance between the sets of classes {*/**} and {***/****} is min{dist(*,***), dist(*,****), dist(**,***), dist(**,****)}. An SVM is then trained to discriminate between the children of the constructed nodes.</paragraph>
                <paragraph>With respect to the example in Figure 1, the classes {*} and {**} are first found to be the most similar, thus forming a node which discriminates between these two classes. In the next iteration, the classes {**} and {***} are found to be the next most similar, producing a new node which discriminates between {*/**} and {***}. Since the most similar sets are considered lower in the tree, the sets closer to the root of the tree are progressively more dissimilar, until the root node discriminates between the two most dissimilar sets of classes.</paragraph>
                <paragraph>Our approach resembles DAGSVMs in that the structure of the decision tree is important. However, unlike DAGSVMs, the MCST-SVM structure is inferred on the basis of similarity between the observed features of the data, which are known, rather than the labels of the classes, which we are trying to predict. We assume that classes with adjacent labels are similar in the feature space, but if this does not happen in the training data, the MCST-SVM will yield a structure that exploits inter-class similarity irrespective of class labels. Further, our reliance on features supports experimentation with different methods for calculating inter-class similarity (Section 3.2). An additional advantage of MCST-SVM classifiers over the other schemes is that MCST-SVM requires only k — 1 decision nodes for a k-class problem (and a maximum of k — 1 decisions to make a prediction). That is, only k — 1 SVMs must be trained, thereby reducing training time.</paragraph>
           

                3.2 Class Similarity Measures
                <paragraph>As mentioned in Section 3.1, the construction of an MCST-SVM classifier requires the computation of a similarity measure between classes. 
                    <context>
                        The <method>MCST-SVM method</method> 
                        <kw>may use</kw> any <data>measure of inter-class similarity</data> during the tree construction stage, and many such methods exist (e.g., linear discriminant analysis to order a tree of classifiers (<cite id="23" function="ack" polarity="neu">Li et al., 2007</cite>)).
                    </context>
                    <context>
                        <author>We</author> 
                        <kw>elected to use</kw> 
                        <method>class prototypes</method> 
                        to 
                        <task>calculate similarity </task>
                        <kw>since they</kw> 
                        <posfeature>have achieved good performance</posfeature> in previous MCST-SVM applications  <cite id="24" function="bas" polarity="pos">(Lorena and de Carvalho, 2005</cite>; <cite id="25" function="bas" polarity="pos">Bickerstaffe et al., 2007</cite>), and are fast to compute over many documents with a large feature space.
                    </context>
                </paragraph>
                <paragraph>Algorithm 1 Constructing the MCST-SVM 1: Let V be a set of graph vertices, where each vertex vi G V represents rating class i and its available training samples. Vi compute Ti, the class representative for rating class i. 2: Let E be a set of graph edges. Vi, j where i = j, compute ei;j G E, the distance between class representatives Ti and Tj. 3: Sort the members of E in ascending order. 4: Vi, let Si = vi, and add Si as a singleton node to the MCST-SVM tree T. 5: Let i = 0 and j = 0 be counting variables. 6: while i less \!V\! — 1 do 7: Select the j-th edge according to the ordering of inter-class distances. 8: if the vertices of the edge are in disjoint sets Sp and Sq then 9: Define Sp as a positive class and Sq as a negative class. 10: Let St = Sp U Sq, and add a new node containing St to T. 11: Connect the left and right branches of the node containing St to the nodes containing Sp and Sq respectively. 12: Remove Sp and Sq. 13: i = i + 1. 17: Train a binary SVM for each non-leaf node of T. 18: Return the MCST-SVM tree T. </paragraph>
                <paragraph>We first determine a representative feature vector for each class, and then calculate the distance between these representative vectors.</paragraph>
                <paragraph>Determining a representative vector. Each review is represented as a vector of boolean attributes, where each attribute indicates the presence or absence of a word or punctuation mark in the text. 
                    <context>
                        <author>We</author> 
                        <kw>elect to use</kw> 
                        <method>boolean attributes</method> 
                        <kw>since they have been shown</kw> 
                        <posfeature>to be advantageous over term-frequency approaches</posfeature> for sentiment detection, particularly when SVMs are employed (<cite id="26" function="bas" polarity="pos">Pang et al., 2002</cite>).
                    </context>
                    We considered two ways of determining a representative vector: centroid and sample selection. • Centroid. Given N boolean feature vectors ai of length n, compute the centroid vector m with values This measure produces a representative vector that contains the proportion of training samples for which each feature occurs. • Sample selection. From the training samples of each class, select one sample which maximises the average Tanimoto coefficient (Tan-imoto, 1957) with respect to all other samples in that class. The Tanimoto coefficient is an extension of cosine similarity which yields the Jaccard coefficient for boolean feature vectors. Given two boolean vectors a and b, the Tanimoto coefficient is defined as where larger values of dt indicate a higher degree of similarity between boolean vectors. This measure chooses a representative vector which on average has the most "overlap" with all other vectors in the class. We use Tanimoto distance, rather than the classical cosine similarity measure, since we employ boolean valued features instead of term-frequency features. We first determine a representative feature vector for each class, and then calculate the distance between these representative vectors. Determining a representative vector. Each review is represented as a vector of boolean attributes, where each attribute indicates the presence or absence of a word or punctuation mark in the text. 
                    
                    <author> We</author> 
                    <kw>elect to use</kw> 
                    <method>boolean attributes</method> 
                    <kw>since they have been shown</kw> 
                    <posfeature>to be advantageous over term-frequency approaches</posfeature> for sentiment detection, particularly when SVMs are employed (<cite id="27" function="bas" polarity="pos">Pang et al., 2002</cite>). 
                
                    We considered two ways of determining a representative vector: centroid and sample selection.</paragraph>
                <paragraph>Calculating distance between vectors. We propose two methods to perform this task: Euclidean distance and the Tanimoto coefficient. • Euclidean distance is used when the vectors that represent a class are centroid vectors (real-valued). • The Tanimoto coefficient is used when the representative vectors of a class are boolean valued. It is calculated using Equation 2.</paragraph>
           

                3.3 Irrelevant Feature Culling
                <paragraph>The MCST-SVM scheme provides a natural mechanism for reducing the dimensionality of feature vectors in order to address the overfitting problem. This is due to the fact that each internal decision node is trained using only the samples that belong to the classes relevant to this node. The reviews for these classes are likely to omit some of the words that appear in the reviews for classes that are relevant to other nodes, in particular in the lower layers of the tree. Consequently, an internal node can be trained using a subset of the features that occur in the entire training dataset. This subset contains only those features which are observed in the samples relevant to training the node in question. Section 4.2 shows that when tested on "real world" datasets, this method can remove thousands of irrelevant features and improve classifier performance, while reducing memory requirements and training times.</paragraph>
            

        </section>
        <section imrad="r">
            <title>4 Experiments and Results</title>
            <paragraph>In this section, we evaluate the MCST-SVM classifier described in Section 3. First, we systematically compare the performance of the different variants of this method: (1) with or without culling irrelevant features, and (2) using the centroid/Euclidean-distance combination or the Tanimoto coefficient to measure inter-class similarity. We then compare the best of these methods with Pang and Lee's (2005). Our results show that a combination of relatively small improvements can achieve a substantial boost in classifier performance, yielding significant improvements over Pang and Lee's results.</paragraph>
            <paragraph>All our experiments are performed with 10-fold cross validation, and the results are assessed using classification accuracy. "Significance" refers to statistical significance determined by a paired t-test, with p less 0.05.</paragraph>
           

                <subtitle>4.1 Dataset</subtitle>
                <paragraph>Our experiments were conducted on the Sentiment Scale dataset (v1.0), which comprises four sub-corpora of 1770, 902, 1307 and 1027 movie reviews with an associated mapping to a three and four-star rating for each review. Each sub-corpus is written by a different author (denoted Author A, B, C and D respectively), thus avoiding calibration error between individual authors and their ratings. 
                    <context>
                        Review texts are automatically filtered to leave only subjective sentences (<kw>motivated by</kw> 
                        <result>the results</result> 
                        <kw>described in</kw> (<cite id="28" function="bas" polarity="pos">Pang and Lee, 2004</cite>));
                    </context>
                    the mean number of words per review in each subjective-filtered sub-corpus is 435, 374, 455 and 292 respectively.</paragraph>
                <paragraph>The root node always considers all classes and therefore considers all features across the whole training dataset. We also have results for mean absolute error (MAE), which confirm our classification accuracy results. http://www.cs.cornell.edu/People/ pabo/moviereview-data.</paragraph>
          
                4.2 MCST-SVM Variants
                <paragraph>Table 1 summarizes the results for the four MCST-SVM variants (the results that are statistically significant compared to the centroid/no-culling option are boldfaced).</paragraph>
                <paragraph>Feature culling. Our results show that feature culling produces some improvement in classifier accuracy for all the three-class and four-class datasets. The impact of feature culling is statistically significant for all the four-class datasets when coupled with the Tanimoto coefficient. However, such an effect was not observed for the centroid/Euclidean-distance measure. In the three-class datasets, the improvements from feature culling are marginal for Authors A, B and C, but statistically significant for Author D (4.61%), both when using the centroid/Euclidean-distance measure and the Tanimoto coefficient. We posit that feature culling affects Author D because it reduces the overfitting problem, which caused the initially poor performance of MCST-SVM without culling on this author's short review texts (the reviews by this author, with 292 words on average, are the shortest in the Sentiment Scale dataset by a large margin, Section 4.1). Despite this improvement, all the MCST-SVM variants (as well as Pang and Lee's methods) exhibit worse performance for Authors B and D, who have shorter reviews, than for Authors A and C.</paragraph>
                <paragraph>The culling of irrelevant features also has the benefit of reducing node training times and facilitating a memory-efficient implementation. For example, without feature culling, the nodes of an MCST-SVM for Author A in the four-class dataset take training samples with 19752 features. In contrast, when irrelevant feature culling is applied, the number of features for each of the two non-root decision nodes reduces to 15445 and 17297. This corresponds to a total space saving of 6582 features ((19752 — 15445) + (19752 — 17297)), yielding an in-memory reduction of 16.7%. Such memory reductions are particularly important for large datasets that may have trouble fitting within typical memory limitations. Node training times are also reduced by up to approximately 10%. In principle, classifiers for the three- and four-class ratings of the Sentiment Scale dataset could be enumerated using optimal stacks of SVMs. However, we wish to directly compare our method with Pang and Lee's (2005). Higher-discrimination datasets (for which optimal stacks are infeasi-ble) will be tested in the future.</paragraph>
                <paragraph>Class similarity measures. As mentioned above, Table 1 shows that the Tanimoto coefficient, coupled with feature culling, yields marginally better results than the centroid/no-culling option for most authors in the three-class dataset, and significantly better results for all the authors in the four-class dataset. The Tanimoto coefficient generally matches or outperforms the centroid/Euclidean-distance measure both with feature culling (Columns 4 and 5 in Table 1) and without feature culling (Columns 2 and 3). However, without feature culling, these improvements are not statistically significant.</paragraph>
                <paragraph>For most cases in the three-star dataset, the tree structures found using the Tanimoto coefficient are identical to those found using the Euclidean-centroid option, hence the performance of the classifier is unchanged. For some validation folds, the Tanimoto coefficient discovered tree structures that differed from those found by the Euclideancentroid option, generally yielding small accuracy improvements (e.g., 0.98% for Author A in the three-star dataset, with feature culling). The Tan-imoto coefficient provides a greater benefit for the four-class dataset. Specifically, when feature culling is used (Columns 4 and 5 in Table 1), accuracy improves by 2.63% and 2.27% for Authors A and B respectively (statistically significant), and by 1.29% and 0.70% for Authors C and D respectively. This may be explained by the fact that there are many more tree structures possible for the four-class case than the three-class case, thereby increasing the impact of the inter-class similarity measure for the four-class case. However, this impact is significant only in conjunction with feature culling.</paragraph>
            
                <subtitle>4.3 Comparison with Pang and Lee (2005)</subtitle>
                
                
                <paragraph>
                    <context>
                        <data>Figure 2</data> 
                        <kw>compares</kw> 
                        <result>the performance</result> 
                        of 
                        <method>the algorithms presented in</method> (<cite id="29" function="con" polarity="neu">Pang and Lee, 2005</cite>) <kw>against</kw> 
                        <method>the performance of the best MCST-SVM variant</method>, which employs feature culling and uses the Tan-imoto coefficient to compute inter-class similarity (Section 4.2).
                    </context>
                    <context>
                        <kw> As per (<cite id="30" function="ack" polarity="neu">Pang and Lee, 2005</cite>), REG indicates SVM-R, which is the baseline ordinal regression method. </kw>
                    </context>
                    The suffix "+PSP" denotes methods that use the metric labeling scheme. 
                    
                    <context>
                        We excluded DAGSVM from our results to maintain consistency with Pang and Lee's experiments. However, according to (<cite id="31" function="ack" polarity="neu">Platt et al., 2000</cite>), <result>the performance difference</result> between DAGSVM and OVA <feature>is not statistically significant</feature>.
                    </context>
                    
                </paragraph> 
                    
         
                <paragraph>
                    <context>
                        Generally, <method>the MCST-SVM </method>
                        is
                        <posfeature>competitive</posfeature> against all the classifiers presented in (<cite id="32" function="con" polarity="pos">Pang and Lee, 2005</cite>), <kw>and in some cases</kw> 
                        <posfeature>significantly outperforms these methods</posfeature>. 
                    </context>
                    Specifically, the hierarchical classifier outperforms OVA+PSP by 7% in the three-class case for Author A (statistically significant), while in the four-class case the MCST-SVM outperforms the best competing methods by 7.72%, 3.89% and 4.98% for Authors A, B, and C respectively (statistically significant). The small improvement of 0.87% for Author D indicates that our approach has the most impact for reviews that contain a relatively large amount of subjective text.</paragraph>
            
        </section>
        <section imrad="d">
            <title>5 Conclusion and Future Work</title>
            <paragraph>This paper described a hierarchical classifier applied to multi-way sentiment detection. The classifier is built by exploiting inter-class similarities to arrange high-performance binary discriminators (SVMs) into a tree structure.Since our inter-class similarity measures are based on sample features, they make the problem of structure determination tractable, and enable experimentation with different similarity measures. The resultant structures provide a natural mechanism to remove irrelevant features at each level of the tree, thus reducing the dimensionality of the feature space, which in turn reduces memory requirements. Importantly, these benefits are achieved while improving upon state-of-the-art classification performance, in particular with respect to higher-discrimination datasets.</paragraph>
            <paragraph>The MCST-SVM classifier can be generalised to any number of classes, and is extendable in the sense that the classifier algorithm employed in each tree node may be replaced by other classifier algorithms as technology advances. The MCST-SVM classifier is also versatile, and may be applied to variations on the rating classification problem, e.g., traditional text classification.</paragraph>
            <paragraph>The MCST-SVM algorithm is not specific to sentiment detection. However, it has several properties which make it particularly suitable for the rating inference problem. Firstly, the MCST-SVM accounts for inter-class similarity and is therefore capable of capturing the ordinal nature of ratings. Secondly, the tree structures permit irrelevant feature culling, which in turn reduces memory requirements and training times.</paragraph>
            <paragraph>Future work will involve testing our approach with higher-discrimination datasets, developing methods to pre-process review texts (e.g., improved negation tagging, and incorporating part-of-speech tagging), and further addressing the problem of overfitting.
                <context>
                    To this effect we will investigate different feature selection algorithms, e.g., (<cite id="33" function="ack" polarity="neu">Weston et al., 2003</cite>), and their utilisation within the classifier trees.
                </context>
                
                <context>
                    <author>We</author> 
                    <kw>also propose</kw> to <kw>consider aspects of</kw> reviews (<cite id="34" function="bas" polarity="pos">Snyder and Barzilay, 2007</cite>), <kw>and investigate other methods</kw> that measure class similarity, such as selecting typical instances (<cite id="35" function="bas" polarity="pos">Zhang, 1992</cite>).
                </context>
            </paragraph>
        </section>
        <section>
            <title>Acknowledgments</title>
            <paragraph>This research is supported in part by ARC grant LP0883416 and GapBuster Worldwide.</paragraph>
        </section>
    </paper>
</annotatedpaper>