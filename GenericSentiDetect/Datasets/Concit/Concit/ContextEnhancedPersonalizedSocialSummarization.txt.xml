<annotatedpaper><paper title="Context-Enhanced Personalized Social Summarization" authors="Po Hu, Donghong Ji, Chong Teng, Yujing Guo" year="2012"> 
<section> 
<title>Context-Enhanced Personalized Social Summarization</title> 
Po Hu1,2, Donghong Ji1 
, Chong Teng1 
 and Yujing Guo1 
(1) Computer School, Wuhan University, China 
(2) Computer School, Central China Normal University, China 
phu@mail.ccnu.edu.cn, donghong_ji2000@yahoo.com.cn, 
tchong616@126.com, yujingguo.ximo@gmail.com   
</section> 
<section> 
<title>Abstract</title> 
<paragraph> 
This work investigates an interesting and challenging task in summarization, i.e., personalized social summarization, which aims to adapt summarization result of a specified document to an intended user based on his interests inferred from social context implicitly. Most existing summarization systems generate a uniform version of summary for different users no matter who is reading or generate personalized summaries employing only the local information in the document and the user profile. This paper proposes a novel unsupervised approach by making use of enhanced social context to aid personalized summary generation. In the proposed method, document expansion, user expansion, and implicit induction of the intended user's interest aspects are achieved simultaneously by adopting a fuzzy tripartite clustering algorithm. And both the informativeness of sentences and the user's interest aspects are incorporated in a unified ranking process. Preliminary experimental results on a social tagging dataset validate the effectiveness of the proposed approach._Keywords: Personalized social summarization, social context, fuzzy tripartite clustering  
</paragraph> 
</section> 
<section imrad="i"> 
<title>1 Introduction</title>
<paragraph> 
With the dramatic growth of the Internet, people are overwhelmed by a large number of accessible documents.In recent years, document summarization has become one of the most important research topics, which aims to address such dilemma by automatically capturing the essential content from document(s) and presenting it to a human reader in a succinct and friendly form. However, most existing summarization methods generate the same summary for different users, regardless of the interests of the readers for whom they are intended. These "one size fits all" methods may perform well in general but may not meet the needs of individuals.  
</paragraph> 
<paragraph> 
Now with the rapid growth of social networking services like Delicious, CiteULike, and Flickr, users are no longer passive consumers of web contents.They can create contents and add metadata. Similarly, web documents no longer exist on their own and they are naturally associated with other documents and diverse users. All these information can be considered as the potential data source for document understanding and personalization.  
</paragraph> 
<paragraph>
	<context> For generating a personalized summary, traditional methods usually require that a user explicitly provides his interest aspects, such as specifying the categories he prefers (<cite id="1" function="wea" polarity="neu">Diaz and Gerv√¢s, 2007</cite>) or clicking a subset of sentences in a document according to his interests (<cite id="2" function="wea" polarity="neu">Yan et al., 2011</cite>). <kw>However</kw>, <person>most users</person> <negfeature>are reluctant to</negfeature> provide such information, thus it is more meaningful to infer a user's interests implicitly.</context>
</paragraph> 
<paragraph> 
To address these concerns, we present an unsupervised approach for personalized summarization. The underlying assumption is that it is beneficial to understand both a single document and a single user better if appropriate social context can be leveraged under some constraints. In this work, the expanded social context used to infer users' interests and enrich document's content is highly selective, which comes from the most similar users and documents. We explored how the size of social context influences the summarization performance, and further demonstrated that appropriate contextual information can ensure better quality and personalization of summaries.  
</paragraph> 
<paragraph> 
To the best of our knowledge, implicitly exploiting social contextual information to collaboratively summarize single document in a personalized way has been rarely investigated in the summarization community. In this work, we propose a novel personalized summarization approach which benefits from three important elements: the interests of like-minded users, the contents of topic-related documents, and semantically-related tags. In the approach, a fuzzy tripartite clustering algorithm is proposed and a multi-manifold ranking algorithm is adopted to generate personalized summary by considering both the informativeness of sentences and the intended user's interests.  
</paragraph> 
<paragraph> 
The main contribution of this paper is summarized as follows: 
</paragraph> 
<paragraph> 
1. we investigate an interesting and challenging summarization task, i.e., personalized social summarization. 
</paragraph> 
<paragraph> 
2. we propose a novel approach making use of expanded social context to capture the intended user's interests, enrich the target document's content, and collaboratively summarize the document in a personalized way. http://delicious.com/ http://www.citeulike.org/ http: / / www.flickr.com/  
</paragraph> 
<paragraph> 
3. we conduct preliminary experiments to validate the effectiveness of the proposed approach on a social tagging dataset and investigate how the expanded social context improves the performance of personalized summarization. 
</paragraph> 
<paragraph> 
The remainder of the paper is organized as follows. The related work is introduced in Section 2. The proposed summarization approach is described in Section 3. Experimental results are shown in Section 4. Section 5 is our conclusion and future work.  
</paragraph> 
</section> 
<section imrad="m"> 
<title>2. Related work</title> 
<paragraph> 
Document summarization has been widely studied for many years. To date, various approaches have been proposed, and our work is under the framework of extractive summarization.  
</paragraph> 
<paragraph> 
	The vast majority of extractive methods identify which sentences are important by making use of unsupervised or supervised learning techniques. <context>In unsupervised <method>methods</method>, feature-based ranking methods <posfeature>are usually based on</posfeature> a <kw>combination of</kw> linguistic and statistical <feature>features</feature> such as term frequency, sentence position, cue words, stigma words, lexical chains, rhetorical structure, topic signatures (<cite id="3" function="use" polarity="pos">Luhn, 1969</cite>; <cite id="4" function="use" polarity="neu">Lin and Hovy, 2000</cite>), etc.</context>
	<context><method>Clustering-based methods</method> usually <kw>select one or more</kw> <posfeature>representative</posfeature> sentences from each subtopic <action>to produce</action> a <result>summary</result> with minimized redundancy and maximized coverage (<cite id="5" function="use" polarity="pos">Nomoto and Matsumoto, 2001</cite>).</context> Graph-based methods have been shown to work well and are becoming more and more popular. <context><method>LexRank</method> (<cite id="6" function="use" polarity="pos">Erkan and Radev, 2004</cite>) and <method>TextRank</method> (<cite id="7" function="use" polarity="pos">Mihalcea and Tarau, 2004</cite>) <kw>are</kw> <posfeature>representative</posfeature> methods adopting models like PageRank and HITS <kw>to estimate the importance of</kw> sentences via the computation of the stationary distribution of a Markov chain or a mutual reinforcement process (<cite id="8" function="use" polarity="pos">Zha, 2002</cite>)</context>.  
</paragraph> 
<paragraph> 
	<context>
	For supervised methods, summarizationis often regarded as a classification task or a sequence labeling task at sentence level, and many supervised learning algorithms have been investigated including Hidden Markov Models (<cite id="8" function="wea" polarity="neg">Conroy and O'leary, 2001</cite>), Support Vector Regression (<cite id="9" function="wea" polarity="neg">You et al., 2011</cite>), Factor Graph Model (<cite id="10" function="wea" polarity="neg">Yang et al., 2011</cite>), etc. <kw>However</kw>, such a supervised learning paradigm <negfeature>often requires a large amount of</negfeature> labeled data, which are <negfeature>not available in most</negfeature> cases.</context>  
</paragraph> 
<paragraph>
	<context> 
	With the rapid growth of online information, <paper>some work</paper> <kw>has began to employ</kw> <data>context</data> <posfeature>to aid</posfeature> summarization, such as contents from external documents (<cite id="11" function="use" polarity="neu">Wan and Yang, 2007</cite>) or cited papers (<cite id="12" function="use" polarity="pos">Mei and Zhai, 2008</cite>; <cite id="13" function="use" polarity="pos">Qazvinian and Radev, 2010</cite>), click-through data or search logs (<cite id="14" function="use" polarity="pos">Sun et al., 2005</cite>), and social tags (<cite id="15" function="use" polarity="pos">Qu and Chen, 2009</cite>; <cite id="16" function="use" polarity="pos">Hu et al., 2011</cite>), comments (<cite id="17" function="use" polarity="pos">Hu et al., 2008</cite>) or discussing tweets (<cite id="18" function="use" polarity="pos">Yang et al., 2011</cite>), etc.</context> 
</paragraph> 
<paragraph> 
However, such methods so far are usually designed for generic summarization and do not take into account the impact of users' interests on summary generation. <context>Besides, in the existing studies, personalized summarization is often conducted with the help of a query (<cite id="19" function="wea" polarity="neg">Sun, 2008</cite>; <cite id="20" function="wea" polarity="neg">You et al., 2011</cite>) or a static user profile (<cite id="21" function="wea" polarity="neg">Diaz and Gerv√¢s, 2007</cite>), and most studies <negfeature>only use</negfeature> the local content from target document(s) or the user profile, <negfeature>with little attention paid to</negfeature> the rich social contextual information affiliated with them.</context>  
</paragraph> 
<paragraph> 
Currently, an increasing number of social websites allow users to enrich the source content. Many documents are now presented together with various feedback information in the form of social tags, comments, or ratings, etc. These usage data can be exploited for personalized summarization since they provide a natural channel to reveal users' interests implicitly.  
</paragraph> 
<paragraph> 
Based on the analysis above, we investigate a challenging task in summarization, i.e., personalized social summarization, and propose an unsupervised approach for this task. The characteristic of our proposed approach is that it can leverage topic-related documents, like-minded users, and semantically-related tags to infer the intended user's interests implicitly and collaboratively summarize the target document in a personalized context-aware way.  
</paragraph> 
</section> 
<section imrad="m"> 
<title>3 Personalized social summarization</title> 
<subsection> 
<title>3.1 overview</title> 
<paragraph> Given a user u (uSU), a document d (dSD), and related social tagging data G (G = (D, U, T, R)), personalized social summarization aims to generate a tailored summary of d for u. Here D, U, and T are documents, users, and tags respectively. R is a ternary relation between them, which denotes the set of annotations of each tag in T to a document in D by a user in U.  
</paragraph> 
<paragraph> 
In most social tagging sites, many documents have been annotated by few tags and most users have only annotated few documents. <context>In this case, existing tag-based <method>summarization methods</method> <negfeature>will fail to</negfeature> produce a personalized summary (<cite id="21" function="wea" polarity="neg">Boydell and Smyth, 2007</cite>; <cite id="22" function="wea" polarity="neg">Zhu et al., 2009</cite>), since the user-related tags <negfeature>may be absent for</negfeature> that document.</context> To address it, we propose to expand both the target document and the intended user with appropriate social context so that the important parts in the document that the intended user may care about can be identified from context.  
</paragraph> 
<paragraph> 
The general framework of our proposed approach consists of three major steps. 
</paragraph> 
<paragraph> 
Step1. Social context identification by document expansion and user expansion .In this step, the given document d is expanded to a small document set Dd(c) by adding a small number of topic-related documents, and the intended user u is expanded to a small user community Uu(c) by adding a small number of like-minded users. Here Dd(c) and Uu(c) are identified as the expanded social context, which is based on the intuition that we would better know a user if we know more like-minded users close to him and we would better understand a document if we read more topic-related documents close to it.  
</paragraph> 
<paragraph> 
Step2. User interest discovery 
In this step, the interest aspects of the intended user u are inferred from the social context Dd(c)and Uu(c) by making use of the social tagging information that the like-minded users gave to the topically related documents. 
</paragraph> 
<paragraph> 
Step3. Personalized summary generation 
In this step, given the expanded document context Dd(c) and the inferred interest aspects, the relationships of all sentences in Dd(c) against each interest aspect are incorporated in a unified ranking process to extract personalized informative sentences from document d. 
</paragraph> 
<title>3.2 Social context identification</title> 
<paragraph> 
In this study, the related social tagging data G, which the target document d and the intended user u belong to, is firstly collected. Then it is used to identify the social context, which can be demonstrated by the example in Figure 1. Topic-related documents of document d Identified social context for d and u Like-minded users of user u Figure 1 - Social context for document d and user u.  
</paragraph> 
<paragraph> 
Since content-related documents are usually annotated with semantically-related tags by users with similar interests,<context> it <kw>is feasible to find</kw><data>topic-related documents</data>, like-minded users, and semantically-related tags simultaneously <kw>by clustering them</kw> collaboratively (<cite id="23" function="use" polarity="neu">Lu et al., 2009</cite>)</context>. Therefore, we propose a fuzzy tripartite clustering algorithm to solve the fuzzy partition issues peculiar in personalized social summarization: a document may cover different subtopics, a user may have diverse interest aspects, and a tag may be a polysemy. The potential benefit of our algorithm is that it can make use of the inherent cluster structure and interactions among the different types of objects to cluster them simultaneously and flexibly. By the algorithm, an object can have a fuzzy membership across clusters and each cluster can be represented by a committee, i.e., a small number of objects with the highest membership for the cluster.  
</paragraph> 
<paragraph> 
Before clustering, each type of object (e.g., document, user, and tag) is first represented by a combined vector. A document di is represented by Di consisting of two components with one denoting user link vector and the other denoting tag link vector. Di = (Di(U), Di(T)), Di(U) = (xij(U) \! j=1,2,...,\!U\!), D/T = (xik(T \! k=1,2,...,\!T\!), where xj (U) denotes the times that di is annotated by user uj, \!U\! denotes the total number of users, xik(T) denotes the times that di has been annotated with tag tk, and \!T\! denotes the total number of tags. User and tag can be represented likewise. Accordingly, the similarity between any two objects of the same type can then be computed by the linear combination of the similarity between their combined vectors. Our proposed fuzzy tripartite clustering algorithm is shown as follows. Algorithm 1: The fuzzy tripartite clustering algorithm. G=(D, U, T, R ): the related social tagging data that document d and user u belong to; Ndc, Nuc, Ntc: the predefined number of document clusters, user clusters, and tag clusters. Output: The fuzzy cluster assignments of documents, users, and tags: Md*, Mu*, and M*, where each object is affiliated with a list of membership values with respect to various clusters. Method: Initialize the fuzzy partition matrices of documents, users, and tags m (0) = \u 1 , For each type of object (e.g. document, user, and tag) do Calculate the centroid vector c(k ) of each cluster based on the current committee of this cluster according to formula (1). For each object do Update the object's membership values u {k) to u (k+1) by the normalized Cosine similarity value between the i-th object and the centroid of the j-th fuzzy object cluster formed in the k-th iteration. Here the computation of the similarity value can be considered as the membership function. Regenerate the committee of each cluster. Until maX'}{\! u1 ^+1) - u' ^') \!}  s or k specified threshold.  
</paragraph> 
<paragraph> 
In the algorithm, u, denotes the membership value for the i-th object in the j-th cluster, s is the termination criterion, which is set as 0.01 in this study. The threshold of maXimum iteration number is set at k=50. Since the 'true' numbers of document clusters, user clusters, and tag clusters are hard to predict in advance, we simply set Ndc, Nuc, and Ntc to the square root of the total number of documents, users, and tags in the related social tagging data respectively. The committee of each cluster is determined by selecting 30 percent of objects which have the highest membership values for the cluster from all the objects of the same type. In the following demonstration, we will take documents as eXamples of objects.  
</paragraph> 
<paragraph> 
Let Cd represent a fuzzy document cluster and Cd(c) represent the committee of Cd (Cd(c) ^ Cd). Since each document can be represented by a user link vector and a tag link vector, we will first consider the user link vectors of these documents. The value of the centroid vector of the document cluster Cd at the user dimension can be calculated by formula (1). where Cu (c) is the committee of a fuzzy user cluster for which user uu has its highest membership value, uj is any user in Cu(c), and di is any document in Cd(c). xj(u) denotes the times that di is tagged by uj. The value of the centroid vector at the tag dimension can be calculated similarly. Accordingly, the similarity between a document di and the centroid of a fuzzy document cluster Cj can be calculated by the linear combination of the Cosine similarity between their user link vectors and tag link vectors.  
</paragraph> 
<paragraph> 
After clustering, we get the cluster assignments of documents, users, and tags, where each document (user, tag) gets a membership value for each cluster. Next, the given document d is expanded to the document context Dd(c) = {d, d1, d2, dm} by adding m topic-related documents with highest membership value for the cluster that d belongs to most likely. Similarly, the intended user u is expanded to the user context Uu(c) = {u, u1, u2, ... , un} by adding n like-minded users with highest membership value for the cluster that u belongs to most likely. Dd(c) and Uu(c)are identified as the expanded social context, aiming to boost information shared by topic-related documents and users with similar interests for personalized summary generation. We will further discuss the variation of performance with different assignment of m and n in Section 4.  
</paragraph> 
<title>3.3 User interest discovery</title> 
<paragraph> 
<context>As a <posfeature>common form of</posfeature> users' online behavior, users' social tagging activities <posfeature>are good at reflecting</posfeature> their interests about document's contents and expressing the general concepts of documents. Previous <paper>work</paper> <kw>has studied</kw> the <kw>utility of</kw> social tags for user interest modeling (<cite id="24" function="use" polarity="pos">Li et al., 2008</cite>) and <kw>confirmed that</kw> a set of semantically related tags can characterize users' interests well (<cite id="25" function="use" polarity="pos">Zhou et al., 2010</cite>).</context>  
</paragraph> 
<paragraph> 
Considering that a user may have diverse interest aspects on a given document and the combination of topic-related documents and like-minded users can provide rich global contextual clues, we propose to model the interests of a user u about a document d by the social tags which have been used to annotate the documents in the document context Dd(c) by the users from the user context Uu(c). The intuitive idea is that users who annotate similar documents may have common interests on the topic shared by these documents, so the tags used by these like-minded users may reveal the latent interests of the intended user about this kind of topic.  
</paragraph> 
<paragraph> 
According to the output of the fuzzy tripartite clustering algorithm, the tags on Dd(c) annotated by Uu(c) may belong to different tag clusters with varying degrees of membership. So we assign these tags into the clusters for which they have highest membership values, and then we can model the intended user's interests by the tag clusters with each indicating one unique interest aspect of the user. Here each cluster consists of one or more semantically-related tags, corresponding to the committee of the relevant tag cluster.  
</paragraph> 
<paragraph> 
Formally, the intended user's interests on the given document can be represented as UMu which can be regarded as multiple subtopics for modelling user's interest aspects. UMu = {pi \! 1 menor i menor Ntu}, where Ntu is the number of interest aspects for user u, and pi is the user's i-th interest aspect for the given document.  
</paragraph> 
<title>3.4 Personalized summary generation</title> 
<paragraph> 
<context><kw>Based on</kw> the identified interest aspects, <author>we</author> <kw>further adopt</kw> <method>multi-manifold ranking algorithm</method> to fuse the sentence relationships against different aspects in a unified ranking process, <kw>which</kw> <posfeature>has performed successfully in</posfeature> the multi-subtopic summarization task (<cite id="26" function="bas" polarity="pos">Wan, 2009</cite>).</context> In this study, we collaboratively summarize the target document by multiple topic-related documents within the document context, since topic-related documents can provide more clues from global context to aid extracting salient summary sentences from the specified document.  
</paragraph> 
<paragraph> 
Formally, given the sentence set S={si \! 1SiSn} of the document context Dd(c) for document d and the k-th interest aspect pk of user u, an affinity matrix wt = [w(l) ] can be built firstly to represent both the relationships among all the n sentences in Dd(c) and the relationship between each sentence and pk. Then Wk is symmetrically normalized by St = Dt"y" -Wt ‚ñ† D~y2. Here w(l) is computed by the Cosine similarity between the i-th sentence and the j-th sentence. Dk is the diagonal matrix with the (i,i)-element equal to the sum of the i-th row of Wk. In this study, there will be Ntu affinity matrices in total since the number of discovered interest aspects for user u is Ntu.  
</paragraph> 
<paragraph> 
Let F represent a ranking function that assigns each element si (0SiSn) a ranking score fi. It can be regarded as a vector F = [f0,..., fn]T. We also define a prior vector Y = [y0,..., yn]T, in which y0=1 for the k-th interest aspect pk and yi=0 (1SiSn) for all the remaining sentences.  
</paragraph> 
<paragraph> 
<context>Next, <author>we</author> <posfeature>can rank all</posfeature> the sentences <kw>by adopting</kw> the <method>multi-manifold ranking algorithm</method> (<cite id="27" function="bas" polarity="pos">Wan, 2009</cite>)</context>, in which the ranking function F is to be learned from Wk (1SkSNtu) and Y. In this study, the constraints from Sk (1S k S Ntu) and Y are naturally fused in a regularized optimization framework defined by the following cost function. where uk (1SkSNtu) and n (0 menor S1) are the trade-off between the smoothness constrains.  0 menor uk, n menor 1 and 2 uk + n = 1.  
</paragraph> 
<paragraph> 
Based on the optimization framework, the optimal ranking function F can be achieved when Q(F) is minimized. In practice, the following iterative form shown in the formula (3) is more commonly used to get the ranking function, in which F(0) is set to Y and we have F(*' = limF(t'.  
</paragraph> 
<paragraph> 
Through the above ranking process, the ranking scores, which denote the user-biased informativeness of sentences, can be obtained. <context>Finally, those sentences highly overlapping with other informative sentences are penalized to remove redundancy (<cite id="28" function="ack" polarity="neu">Wan and Yang, 2007</cite>)</context>, and the sentences with high overall scores are chosen from document d into the summary.  
</paragraph> 
</subsection> 
</section> 
<section imrad="r"> 
<title>4 Experiments</title> 
<subsection> 
<title>4.1 Dataset</title> 
<paragraph> 
Since there is no benchmark dataset available for the task of personalized social summarization, we collected data from Delicious, one of the most popular social tagging websites. Specifically, we extracted a set of web documents, bookmark tags, and the users who bookmarked these documents to serve as the experimental dataset.  
</paragraph> 
<paragraph> 
Starting with predefined seed tags, we extracted the top bookmarked documents for each tag and extracted the users and tags used to annotate each of the documents. The result is a collection consisting of 204 bookmarked documents and 2186 unique social tags that were used to annotate these documents by 1696 users. To guarantee the genre consistency, all the documents were crawled from news sources such as CNN, BBC, New York Times, etc.  
</paragraph> 
<title>4.2 Evaluation methods</title> 
<paragraph> 
In this paper, both manual evaluation method and automatic evaluation method are adopted. For each document in the dataset, we randomly select one to five users as the intended users from all the users who annotated the document with multiple social tags.  
</paragraph> 
<subsection> 
<title>Manual evaluation</title> 
<paragraph> 
First, we must admit that it would be better to use personalized reference summaries for evaluation. However, it would be quite difficult to get personalized summaries from the actual users of Delicious. The alternative way is to get the external judgments from several judges and take average of their ratings so that we know that multiple people would consider that this summary is relevant or tailored for the intended user to a certain extent. How to develop a better test collection for personalized summarization from the perspective of social context is an important future direction of our research.  
</paragraph> 
<paragraph> 
In this study, three evaluators are requested to express their judgments over all automatically generated summaries based on both the content they deem to be important for the target document and how "personal" each one is according to the interests of the intended user. We provide each evaluator the intended user's background knowledge collected by calling the official Delicious.com API and parsing its RSS feeds. The provided information includes all the open document bookmarks of intended users and all the tags they used to annotate the documents including the target document to be summarized. Evaluators can also access the content of the corresponding document by clicking the URL in each bookmark.  
</paragraph> 
<paragraph> 
In the evaluation process, evaluators are instructed to give an overall score to each summary. The overall score reflects the comprehensive quality of a summary including not only the evaluation for the general content of the generated summary but also the degree of compliance with the intended user's personalized interests and foci.  
</paragraph> 
<paragraph> 
All the judgment scores are rated in a 5-point scale, where "1" for "very poor", "2" for "poor", "3" for "barely acceptable", "4" for "good", and "5" for "very good". Evaluators are allowed to judge at any scores between 1 and 5, e.g. 3.5. 
</paragraph> 
<title>4.2.2 Automatic evaluation</title> 
<paragraph> 
Considering that manual evaluation is generally time consuming and labour-intensive, we also adopt automatic evaluation strategy.  
</paragraph> 
<paragraph> 
For each intended user of the target document, we randomly divide the social tags he assigned to the document into two approximately equal parts: a training set and a test set. The former is used to generate personalized social summary on the document for the user, and the latter is used to evaluate the generated summary based on the recall against the tags in the test set, making sure to remove the tags occurring in the training set from the test set.  
</paragraph> 
<paragraph> 
The idea of this kind of evaluation strategy is to look for overlaps between the generated personalized social summary and those unseen tags used by the intended user on the given document, since the tags in the test set correspond to an alternative, but previously unseen, point of interests for the intended user with respect to the target document. 
</paragraph> 
<paragraph> 
The automatic evaluation experiments were conducted in the cross validation procedure, and the average recall score was recorded. Intuitively, the higher the average recall score is, the more the generated summaries are in line with the interests of the intended users.  
</paragraph> 
</subsection> 
<title>4.3 Baselines</title> 
<paragraph> 
In the experiments, we compare our proposed approach with several baseline methods. For fair comparison, we conduct the same preprocessing for all the methods including sentence segmentation, word stemming, and redundancy removing.  
</paragraph> 
<paragraph> 
Random: It extracts sentences randomly from each document. 
</paragraph> 
<paragraph> 
<context>OTS: It is an <tool>open source summarizer</tool> integrating shallow <method>NLP techniques</method> with <task>statistical word frequency analysis</task> <kw>for</kw> sentence scoring (<cite id="29" function="use" polarity="neu">Nadav, 2003</cite>).</context> 
</paragraph> 
<paragraph> 
MEAD: It ranks sentences according to the combination of features including centroid value, positional value, and first-sentence overlap (<cite id="30">Radev et al., 2000</cite>). 
</paragraph> 
<paragraph> 
<tool>LexRank</tool>: <kw>It first constructs</kw> a sentence <result>affinity graph</result> based on the Cosine similarity between sentences in a document, and <kw>then extracts a few</kw> informative sentences based on eigenvector centrality (<cite id="31" function="use" polarity="neu">Erkan and Radev, 2004</cite>). 
</paragraph> 
<paragraph> 
DcontextLexRank: It is an extension of the original LexRank method by firstly ranking sentences on the document context which the target document belongs to, and then extracting sentences with highest ranking scores from the target document. 
</paragraph> 
<paragraph> 
PSocialSum: It is our proposed approach using expanded social context to capture the intended user's interests, enrich the target document's content, and collaboratively summarize the target document in a personalized way. 
</paragraph> 
<title>4.4 Overall comparison results </title> 
<subsection> 
<title>4.4.1 Parameter settings</title> 
<paragraph> 
The parameters m and n, i.e., the number of expanded topic-related documents in the document context Dd(c) and the number of expanded like-minded users in the user context Uu(c), are set as the number of elements in the corresponding committee of the cluster that document d or user u belongs to most likely. 
</paragraph> 
<paragraph> 
In the multi-manifold ranking process of our approach, parameters uk and tj are the smoothness constraint and fitting constraint respectively, which control the trade-off between the impact from Sk (i.e., both the relationships among all the sentences in the document context and the relationship between each sentence and the k-th interest aspect of user u) and the impact from Y (i.e. the prior vector set for the k-th interest aspect and all the remaining sentences). <context>In the following experiments, the <feature>regularization parameter</feature> tj <kw>for</kw> the fitting constraint <kw>is fixed at</kw> 0.01, the same as in (<cite id="32" function="use" polarity="neu">Wan, 2009</cite>)</context>, and uk is set to the normalized Cosine similarity between the corresponding vectors of pk and Dd(c).  
</paragraph> 
<title>Experimental results</title> 
<paragraph> 
In the experiments, for each document, we generate multiple different personalized summaries for each of the intended users by our approach. For comparison purpose, each document in the dataset is also summarized using all the baseline methods described in Section 4.3.  
</paragraph> 
<paragraph> 
First, we conducted the manual evaluation and the average overall scores of multiple evaluators on all the generated summaries are listed in Table 1. Table 1 -The average overall scores of multiple evaluators. From Table 1, it can be found that Random has the worst summarization performance.  
</paragraph> 
<paragraph> 
LexRank and DcontextLexRank perform better than those of MEAD and OTS. This is mainly because both LexRank and DcontextLexRank make use of the inter-relationship between sentences to rank them globally, while MEAD and OTS only depend on the combination of some local features.  
</paragraph> 
<paragraph> 
DcontextLexRank outperforms LexRank in our experiments, which indicates the use of appropriate document context for sentence ranking is an improvement over the use of single document alone which lacks the support of external clues from the similar documents. 
</paragraph> 
<paragraph> 
Note that all these baseline methods generate the summary based on either the given document itself or the document context, regardless of the intended user's interests. Our proposed approach shows significantly better performance on evaluators' ratings. And the rating difference between PSocialSum and other baselines is significant at the 95% statistical confidence level in all cases. This indicates that consideration of user's interests is critical for generating a better personalized summary, and the improvement achieved is mainly attributed to the personalization aspect as well as informative content.  
</paragraph> 
<paragraph> 
We also find that the evaluator judgments on MEAD, LexRank, and DcontextLexRank are of little significant difference at the 95% confidence interval, which illustrates that the general summaries generated by these comparable baselines can convey the important information of a document, and different evaluators may have some agreement on the quality of its content, although all of these methods do not consider the intended user's interest at all. 
</paragraph> 
<paragraph> 
Next, we conducted the automatic evaluation by computing the average recall scores against the tags in the corresponding test set for all the resulting summaries. The process is repeated across multiple different random splits of training and test set. The average recall scores are reported in Table 2. Table 2 - The average recall scores.  
</paragraph> 
<paragraph> 
From Table 2, we see that the summarization performance of PSocialSum is consistently better than those of other baselines. Such results also demonstrate that by leveraging part of the social tagging information of the intended users, we can generate better summaries which are more in accordance with the latent interests of them, compared to other summarizers which generate the static summaries ignoring the social contextual information.  
</paragraph> 
</subsection> 
<title>4.5 Impact of parameters</title> 
<paragraph> 
In this section, to investigate how the size m and n of the expanded topic-related documents and the expanded like-minded users influence the performance of PSocialSum, we conduct the following experiments with different values. 
</paragraph> 
<paragraph> 
Considering that m and n in this study are dynamically related to the predefined percentage of objects which have the highest membership values for the cluster from all the objects of the same type, in the experiment, we set the predefined percentage value related with m and n ranging from 10% to 80% with step length 10%, indicating the corresponding percentage of documents or users are selected for the expanded document set or user set. Figure 2 shows the average recall scores against the tags in the test set for PSocialSum with different percentage values. The predefined percentage value associated with m and n Figure 2 -The average recall scores of PSocialSum vs. the predefined percentage value related with m and n.  
</paragraph> 
<paragraph> 
From Figure 2, it can be seen that when the percentage value increases from 10% to 30%, the recall increases gradually, and reaches the global maximum when it is set to 30%. When we adjust the percentage value from 30% to 80%, the recall starts to decay. The result demonstrates that appropriate document context and user context are beneficial for improving personalized summarization performance, yet a large size of the expanded context may deteriorate the performance because it may include a lot of irrelevant information even noise.  
</paragraph> 
</subsection> 
</section> 
<section imrad="d"> 
<title>Conclusion</title> 
<paragraph> 
In this paper, we present a study of personalized social summarization, and propose a novel unsupervised approach. The approach makes use of expanded social context to capture the intended user's interests, enrich the target document's content, and collaboratively summarize the target document in a personalized context-aware way. Preliminary experimental results demonstrate the effectiveness of the proposed approach.  
</paragraph> 
<paragraph> 
In practice, the dimensions and variability of users, documents, and tags from most social network websites may be quite high, so in future work, we plan to combine link structure association analysis and feature selection to effectively deal with high-dimensional online tripartite clustering dynamically. And more social contextual information such as social relationships among users will also be investigated. For simplicity, this method represents each object with a vector of two sets of features, and this kind of representation would inevitably result in information loss to a certain extent. Therefore, we plan to try better alternatives such as hypergraph or tensor model, and make effort to improve the existing work on content or social network-based user interest modeling. Furthermore, it would be more convincing to resort to crowdsourcing technique to evaluate the proposed approach by a large number of real users on the social tagging websites and on larger-scale social data set. Acknowledgments  This work was supported by the National Natural Science Foundation of China (No. 61133012, 61173062, 61070082, 61070083, 61070243), the major program of the National Social Science Foundation of China (No. 11&amp;ZD189), and the Post-70s Scholars Academic Development Program of Wuhan University.  
</paragraph> 
</section> 
</paper> 
 
 
 
 
</annotatedpaper>